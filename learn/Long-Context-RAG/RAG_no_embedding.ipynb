{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 法律问答中的长上下文 RAG：\n",
    "\n",
    "构建一个智能代理系统，从复杂的法律文档中回答问题。\n",
    "\n",
    "## 下载document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/blackink/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "import tiktoken\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Download nltk data if not already present\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(pdf_path: str) -> str:\n",
    "    \"\"\"Load a document from a URL and return its text content.\"\"\"\n",
    "\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    full_text = \"\"\n",
    "\n",
    "\n",
    "    max_page = 100  # Page cutoff before section 1000 (Interferences)\n",
    "    for i, page in enumerate(pdf_reader.pages):\n",
    "        if i >= max_page:\n",
    "            break\n",
    "        full_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    # Count words and tokens\n",
    "    word_count = len(re.findall(r'\\b\\w+\\b', full_text))\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
    "    token_count = len(tokenizer.encode(full_text))\n",
    "\n",
    "    print(f\"Document loaded: {len(pdf_reader.pages)} pages, {word_count} words, {token_count} tokens\")\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded: 1194 pages, 56856 words, 82496 tokens\n",
      "\n",
      "Document preview (first 500 chars):\n",
      "--------------------------------------------------\n",
      "TRADEMARK TRIAL AND\n",
      "APPEAL BOARD MANUAL\n",
      "OF PROCEDURE (TBMP)\n",
      " June 2024\n",
      "June   2024\n",
      "United States Patent and Trademark Office\n",
      "PREFACE TO THE JUNE 2024 REVISION\n",
      "The June 2024 revision of the Trademark Trial and Appeal Board Manual of Procedure is an update of the\n",
      "June 2023 edition. This update is moderate in nature and incorporates relevant case law issued between March\n",
      "3, 2023 and March 1, 2024.\n",
      "The title of the manual is abbreviated as “TBMP.” A citation to a section of the manual may be written\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the document\n",
    "pdf_path = \"../../data/tbmp-Master-June2024.pdf\"\n",
    "document_text = load_document(pdf_path)\n",
    "\n",
    "# Show the first 500 characters\n",
    "print(\"\\nDocument preview (first 500 chars):\")\n",
    "print(\"-\" * 50)\n",
    "print(document_text[:500])\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本切分：高阶的20段分割器（依据Tokens大小限制）\n",
    "\n",
    "现在，我们将创建一个高阶文本切分，用于将文档分割成20个片段。保证每个最小单元都是句子同时确保每个片段具有最小的Token数量。\n",
    "\n",
    "> `20` 是针对该特定文档和任务通过经验确定的分段数。对于其他文档，可能需要根据其大小和结构进行调整。分段数量越高，粒度越细。\n",
    "> 核心原则是在分割文档的不同部分后，**让语言模型自行判断哪些部分是相关的**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split document into 20 chunks\n",
      "Chunk 0: 5681 tokens\n",
      "Chunk 1: 4722 tokens\n",
      "Chunk 2: 3519 tokens\n",
      "Chunk 3: 4197 tokens\n",
      "Chunk 4: 3627 tokens\n",
      "Chunk 5: 3491 tokens\n",
      "Chunk 6: 3132 tokens\n",
      "Chunk 7: 4664 tokens\n",
      "Chunk 8: 3734 tokens\n",
      "Chunk 9: 4707 tokens\n",
      "Chunk 10: 4189 tokens\n",
      "Chunk 11: 3413 tokens\n",
      "Chunk 12: 3834 tokens\n",
      "Chunk 13: 5516 tokens\n",
      "Chunk 14: 4785 tokens\n",
      "Chunk 15: 3916 tokens\n",
      "Chunk 16: 4000 tokens\n",
      "Chunk 17: 3470 tokens\n",
      "Chunk 18: 4598 tokens\n",
      "Chunk 19: 3451 tokens\n"
     ]
    }
   ],
   "source": [
    "# Global tokenizer name to use consistently throughout the code\n",
    "TOKENIZER_NAME = \"o200k_base\"\n",
    "\n",
    "def split_into_20_chunks(text: str, min_tokens: int = 500) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Split text into up to 20 chunks, respecting sentence boundaries and ensuring\n",
    "    each chunk has at least min_tokens (unless it's the last chunk).\n",
    "    \n",
    "    Args:\n",
    "        text: The text to split\n",
    "        min_tokens: The minimum number of tokens per chunk (default: 500)\n",
    "    \n",
    "    Returns:\n",
    "        A list of dictionaries where each dictionary has:\n",
    "        - id: The chunk ID (0-19)\n",
    "        - text: The chunk text content\n",
    "    \"\"\"\n",
    "    # First, split the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Get tokenizer for counting tokens\n",
    "    tokenizer = tiktoken.get_encoding(TOKENIZER_NAME)\n",
    "    \n",
    "    # Create chunks that respect sentence boundaries and minimum token count\n",
    "    chunks = []\n",
    "    current_chunk_sentences = []\n",
    "    current_chunk_tokens = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Count tokens in this sentence\n",
    "        sentence_tokens = len(tokenizer.encode(sentence))\n",
    "        \n",
    "        # If adding this sentence would make the chunk too large AND we already have the minimum tokens,\n",
    "        # finalize the current chunk and start a new one\n",
    "        if (current_chunk_tokens + sentence_tokens > min_tokens * 2) and current_chunk_tokens >= min_tokens:\n",
    "            chunk_text = \" \".join(current_chunk_sentences)\n",
    "            chunks.append({\n",
    "                \"id\": len(chunks),  # Integer ID instead of string\n",
    "                \"text\": chunk_text\n",
    "            })\n",
    "            current_chunk_sentences = [sentence]\n",
    "            current_chunk_tokens = sentence_tokens\n",
    "        else:\n",
    "            # Add this sentence to the current chunk\n",
    "            current_chunk_sentences.append(sentence)\n",
    "            current_chunk_tokens += sentence_tokens\n",
    "    \n",
    "    # Add the last chunk if there's anything left\n",
    "    if current_chunk_sentences:\n",
    "        chunk_text = \" \".join(current_chunk_sentences)\n",
    "        chunks.append({\n",
    "            \"id\": len(chunks),  # Integer ID instead of string\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "    \n",
    "    # If we have more than 20 chunks, consolidate them\n",
    "    if len(chunks) > 20:\n",
    "        # Recombine all text\n",
    "        all_text = \" \".join(chunk[\"text\"] for chunk in chunks)\n",
    "        # Re-split into exactly 20 chunks, without minimum token requirement\n",
    "        sentences = sent_tokenize(all_text)\n",
    "        sentences_per_chunk = len(sentences) // 20 + (1 if len(sentences) % 20 > 0 else 0)\n",
    "        \n",
    "        chunks = []\n",
    "        for i in range(0, len(sentences), sentences_per_chunk):\n",
    "            # Get the sentences for this chunk\n",
    "            chunk_sentences = sentences[i:i+sentences_per_chunk]\n",
    "            # Join the sentences into a single text\n",
    "            chunk_text = \" \".join(chunk_sentences)\n",
    "            # Create a chunk object with ID and text\n",
    "            chunks.append({\n",
    "                \"id\": len(chunks),  # Integer ID instead of string\n",
    "                \"text\": chunk_text\n",
    "            })\n",
    "    \n",
    "    # Print chunk statistics\n",
    "    print(f\"Split document into {len(chunks)} chunks\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        token_count = len(tokenizer.encode(chunk[\"text\"]))\n",
    "        print(f\"Chunk {i}: {token_count} tokens\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Split the document into 20 chunks with minimum token size\n",
    "document_chunks = split_into_20_chunks(document_text, min_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关性判断路由（调用工具）----GPT-4.1-mini\n",
    "现在，我们来创建一个路由函数，用于选择相关的文本块，并维护一个记录。\n",
    "\n",
    "维护一个推理记录可以让模型在推理过程中持续记录决策标准和推理依据。、\n",
    "使用GPT-4.1-mini采用了两步实验：\n",
    "- 第一步要求模型通过工具调用（tool_choice=\"required\"）来更新推理记录\n",
    "- 第二步则请求模型以结构化 JSON 格式输出所选择的文本块。\n",
    "这种方法可以让我们更清楚地了解模型的推理过程，同时保证为下游处理提供一致、结构化的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "def route_chunks(question: str, chunks: List[Dict[str, Any]], \n",
    "                depth: int, scratchpad: str = \"\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ask the model which chunks contain information relevant to the question.\n",
    "    Maintains a scratchpad for the model's reasoning.\n",
    "    Uses structured output for chunk selection and required tool calls for scratchpad.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        chunks: List of chunks to evaluate\n",
    "        depth: Current depth in the navigation hierarchy\n",
    "        scratchpad: Current scratchpad content\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with selected IDs and updated scratchpad\n",
    "    \"\"\"\n",
    "    print(f\"\\n==== ROUTING AT DEPTH {depth} ====\")\n",
    "    print(f\"Evaluating {len(chunks)} chunks for relevance\")\n",
    "    \n",
    "    # Build system message\n",
    "    system_message = \"\"\"You are an expert document navigator. Your task is to:\n",
    "1. Identify which text chunks might contain information to answer the user's question\n",
    "2. Record your reasoning in a scratchpad for later reference\n",
    "3. Choose chunks that are most likely relevant. Be selective, but thorough. Choose as many chunks as you need to answer the question, but avoid selecting too many.\n",
    "\n",
    "First think carefully about what information would help answer the question, then evaluate each chunk.\n",
    "\"\"\"\n",
    "\n",
    "    # Build user message with chunks and current scratchpad\n",
    "    user_message = f\"QUESTION: {question}\\n\\n\"\n",
    "    \n",
    "    if scratchpad:\n",
    "        user_message += f\"CURRENT SCRATCHPAD:\\n{scratchpad}\\n\\n\"\n",
    "    \n",
    "    user_message += \"TEXT CHUNKS:\\n\\n\"\n",
    "    \n",
    "    # Add each chunk to the message\n",
    "    for chunk in chunks:\n",
    "        user_message += f\"CHUNK {chunk['id']}:\\n{chunk['text']}\\n\\n\"\n",
    "    \n",
    "    # Define function schema for scratchpad tool calling\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"name\": \"update_scratchpad\",\n",
    "            \"description\": \"Record your reasoning about why certain chunks were selected\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Your reasoning about the chunk(s) selection\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Define JSON schema for structured output (selected chunks)\n",
    "    text_format = {\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"selected_chunks\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"chunk_ids\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"integer\"},\n",
    "                        \"description\": \"IDs of the selected chunks that contain information to answer the question\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"chunk_ids\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # First pass: Call the model to update scratchpad (required tool call)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message + \"\\n\\nFirst, you must use the update_scratchpad function to record your reasoning.\"}\n",
    "    ]\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"required\"\n",
    "    )\n",
    "    \n",
    "    # Process the scratchpad tool call\n",
    "    new_scratchpad = scratchpad\n",
    "    \n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type == \"function_call\" and tool_call.name == \"update_scratchpad\":\n",
    "            args = json.loads(tool_call.arguments)\n",
    "            scratchpad_entry = f\"DEPTH {depth} REASONING:\\n{args.get('text', '')}\"\n",
    "            if new_scratchpad:\n",
    "                new_scratchpad += \"\\n\\n\" + scratchpad_entry\n",
    "            else:\n",
    "                new_scratchpad = scratchpad_entry\n",
    "            \n",
    "            # Add function call and result to messages\n",
    "            messages.append(tool_call)\n",
    "            messages.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": tool_call.call_id,\n",
    "                \"output\": \"Scratchpad updated successfully.\"\n",
    "            })\n",
    "    \n",
    "    # Second pass: Get structured output for chunk selection\n",
    "    messages.append({\"role\": \"user\", \"content\": \"Now, select the chunks that could contain information to answer the question. Return a JSON object with the list of chunk IDs.\"})\n",
    "    \n",
    "    response_chunks = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=messages,\n",
    "        text=text_format\n",
    "    )\n",
    "    \n",
    "    # Extract selected chunk IDs from structured output\n",
    "    selected_ids = []\n",
    "    if response_chunks.output_text:\n",
    "        try:\n",
    "            # The output_text should already be in JSON format due to the schema\n",
    "            chunk_data = json.loads(response_chunks.output_text)\n",
    "            selected_ids = chunk_data.get(\"chunk_ids\", [])\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse structured output as JSON\")\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Selected chunks: {', '.join(str(id) for id in selected_ids)}\")\n",
    "    print(f\"Updated scratchpad:\\n{new_scratchpad}\")\n",
    "    \n",
    "    return {\n",
    "        \"selected_ids\": selected_ids,\n",
    "        \"scratchpad\": new_scratchpad\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分层查询相关性\n",
    "\n",
    "现在，我们来创建一个逐层查询，用于深入遍历文档。**max_depth**是指允许向下递归的最大层数（同时需要注意最小 token 数量的限制）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_to_paragraphs(document_text: str, question: str, max_depth: int = 1) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Navigate through the document hierarchy to find relevant paragraphs.\n",
    "    \n",
    "    Args:\n",
    "        document_text: The full document text\n",
    "        question: The user's question\n",
    "        max_depth: Maximum depth to navigate before returning paragraphs (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with selected paragraphs and final scratchpad\n",
    "    \"\"\"\n",
    "    scratchpad = \"\"\n",
    "    \n",
    "    # Get initial chunks with min 500 tokens\n",
    "    chunks = split_into_20_chunks(document_text, min_tokens=500)\n",
    "    \n",
    "    # Navigator state - track chunk paths to maintain hierarchy\n",
    "    chunk_paths = {}  # Maps numeric IDs to path strings for display\n",
    "    for chunk in chunks:\n",
    "        chunk_paths[chunk[\"id\"]] = str(chunk[\"id\"])\n",
    "    \n",
    "    # Navigate through levels until max_depth or until no chunks remain\n",
    "    for current_depth in range(max_depth + 1):\n",
    "        # Call router to get relevant chunks\n",
    "        result = route_chunks(question, chunks, current_depth, scratchpad)\n",
    "        \n",
    "        # Update scratchpad\n",
    "        scratchpad = result[\"scratchpad\"]\n",
    "        \n",
    "        # Get selected chunks\n",
    "        selected_ids = result[\"selected_ids\"]\n",
    "        selected_chunks = [c for c in chunks if c[\"id\"] in selected_ids]\n",
    "        \n",
    "        # If no chunks were selected, return empty result\n",
    "        if not selected_chunks:\n",
    "            print(\"\\nNo relevant chunks found.\")\n",
    "            return {\"paragraphs\": [], \"scratchpad\": scratchpad}\n",
    "        \n",
    "        # If we've reached max_depth, return the selected chunks\n",
    "        if current_depth == max_depth:\n",
    "            print(f\"\\nReturning {len(selected_chunks)} relevant chunks at depth {current_depth}\")\n",
    "            \n",
    "            # Update display IDs to show hierarchy\n",
    "            for chunk in selected_chunks:\n",
    "                chunk[\"display_id\"] = chunk_paths[chunk[\"id\"]]\n",
    "                \n",
    "            return {\"paragraphs\": selected_chunks, \"scratchpad\": scratchpad}\n",
    "        \n",
    "        # Prepare next level by splitting selected chunks further\n",
    "        next_level_chunks = []\n",
    "        next_chunk_id = 0  # Counter for new chunks\n",
    "        \n",
    "        for chunk in selected_chunks:\n",
    "            # Split this chunk into smaller pieces\n",
    "            sub_chunks = split_into_20_chunks(chunk[\"text\"], min_tokens=200)\n",
    "            \n",
    "            # Update IDs and maintain path mapping\n",
    "            for sub_chunk in sub_chunks:\n",
    "                path = f\"{chunk_paths[chunk['id']]}.{sub_chunk['id']}\"\n",
    "                sub_chunk[\"id\"] = next_chunk_id\n",
    "                chunk_paths[next_chunk_id] = path\n",
    "                next_level_chunks.append(sub_chunk)\n",
    "                next_chunk_id += 1\n",
    "        \n",
    "        # Update chunks for next iteration\n",
    "        chunks = next_level_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split document into 20 chunks\n",
      "Chunk 0: 5681 tokens\n",
      "Chunk 1: 4722 tokens\n",
      "Chunk 2: 3519 tokens\n",
      "Chunk 3: 4197 tokens\n",
      "Chunk 4: 3627 tokens\n",
      "Chunk 5: 3491 tokens\n",
      "Chunk 6: 3132 tokens\n",
      "Chunk 7: 4664 tokens\n",
      "Chunk 8: 3734 tokens\n",
      "Chunk 9: 4707 tokens\n",
      "Chunk 10: 4189 tokens\n",
      "Chunk 11: 3413 tokens\n",
      "Chunk 12: 3834 tokens\n",
      "Chunk 13: 5516 tokens\n",
      "Chunk 14: 4785 tokens\n",
      "Chunk 15: 3916 tokens\n",
      "Chunk 16: 4000 tokens\n",
      "Chunk 17: 3470 tokens\n",
      "Chunk 18: 4598 tokens\n",
      "Chunk 19: 3451 tokens\n",
      "\n",
      "==== ROUTING AT DEPTH 0 ====\n",
      "Evaluating 20 chunks for relevance\n",
      "Selected chunks: 3, 4, 7, 11, 13\n",
      "Updated scratchpad:\n",
      "DEPTH 0 REASONING:\n",
      "The question asks about the format and signature handling of a motion to compel discovery before the Trademark Trial and Appeal Board (TTAB). Relevant information would likely be in sections discussing motions, signature requirements, electronic filing procedures, and service of papers.\n",
      "\n",
      "Chunks 3 and 4 discuss signature of submissions (§ 106.02) and form of submissions (§ 106.03) respectively, important for understanding how motions (including possibly motions to compel discovery) should be formatted and signed.\n",
      "\n",
      "Chunk 13 continues the discussion of signature and disciplinary provisions, emphasizing certification by signatory.\n",
      "\n",
      "Chunks 13 also discusses disciplinary sanctions related to signatures – useful for understanding signature handling.\n",
      "\n",
      "Chunks 113 and 113.01 to 113.06 discuss service of papers including motions, requirements for proof of service, methods of service, and certificates of service, which would be relevant for motions to compel discovery.\n",
      "\n",
      "Chunk 112 describes times for taking action after service which may provide context on timing but less about form.\n",
      "\n",
      "Chunks 0 through 2 provide introductory and general procedural context including references to Federal Rules, but no specific format for motions to compel discovery.\n",
      "\n",
      "Chunks 5-7 describe electronic filing using ESTTA, attachments, and service with proof – critical for current practice.\n",
      "\n",
      "Chunks 18 and 19 discuss extensions of time to oppose, which are less central to motions.\n",
      "\n",
      "Overall, to answer the question well, the best chunks are:\n",
      "- 3 (Signature of submissions)\n",
      "- 4 (Form of submissions)\n",
      "- 7 (Attachments to ESTTA filings)\n",
      "- 113 (Service of papers)\n",
      "- 13 (Signature and certificate for correspondence + disciplinary provisions)\n",
      "\n",
      "Other chunks could add context if needed, but these most directly address the formatting and signature requirements relevant to a motion to compel discovery.\n",
      "Split document into 11 chunks\n",
      "Chunk 0: 401 tokens\n",
      "Chunk 1: 435 tokens\n",
      "Chunk 2: 355 tokens\n",
      "Chunk 3: 383 tokens\n",
      "Chunk 4: 396 tokens\n",
      "Chunk 5: 364 tokens\n",
      "Chunk 6: 397 tokens\n",
      "Chunk 7: 402 tokens\n",
      "Chunk 8: 385 tokens\n",
      "Chunk 9: 338 tokens\n",
      "Chunk 10: 339 tokens\n",
      "Split document into 10 chunks\n",
      "Chunk 0: 389 tokens\n",
      "Chunk 1: 387 tokens\n",
      "Chunk 2: 354 tokens\n",
      "Chunk 3: 396 tokens\n",
      "Chunk 4: 384 tokens\n",
      "Chunk 5: 368 tokens\n",
      "Chunk 6: 208 tokens\n",
      "Chunk 7: 386 tokens\n",
      "Chunk 8: 402 tokens\n",
      "Chunk 9: 353 tokens\n",
      "Split document into 13 chunks\n",
      "Chunk 0: 399 tokens\n",
      "Chunk 1: 394 tokens\n",
      "Chunk 2: 295 tokens\n",
      "Chunk 3: 369 tokens\n",
      "Chunk 4: 383 tokens\n",
      "Chunk 5: 399 tokens\n",
      "Chunk 6: 393 tokens\n",
      "Chunk 7: 372 tokens\n",
      "Chunk 8: 365 tokens\n",
      "Chunk 9: 365 tokens\n",
      "Chunk 10: 394 tokens\n",
      "Chunk 11: 375 tokens\n",
      "Chunk 12: 159 tokens\n",
      "Split document into 9 chunks\n",
      "Chunk 0: 403 tokens\n",
      "Chunk 1: 393 tokens\n",
      "Chunk 2: 360 tokens\n",
      "Chunk 3: 386 tokens\n",
      "Chunk 4: 353 tokens\n",
      "Chunk 5: 407 tokens\n",
      "Chunk 6: 377 tokens\n",
      "Chunk 7: 353 tokens\n",
      "Chunk 8: 380 tokens\n",
      "Split document into 16 chunks\n",
      "Chunk 0: 240 tokens\n",
      "Chunk 1: 402 tokens\n",
      "Chunk 2: 401 tokens\n",
      "Chunk 3: 370 tokens\n",
      "Chunk 4: 373 tokens\n",
      "Chunk 5: 401 tokens\n",
      "Chunk 6: 346 tokens\n",
      "Chunk 7: 308 tokens\n",
      "Chunk 8: 384 tokens\n",
      "Chunk 9: 393 tokens\n",
      "Chunk 10: 345 tokens\n",
      "Chunk 11: 237 tokens\n",
      "Chunk 12: 338 tokens\n",
      "Chunk 13: 378 tokens\n",
      "Chunk 14: 390 tokens\n",
      "Chunk 15: 207 tokens\n",
      "\n",
      "==== ROUTING AT DEPTH 1 ====\n",
      "Evaluating 59 chunks for relevance\n",
      "Selected chunks: 0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 25, 26, 27\n",
      "Updated scratchpad:\n",
      "DEPTH 0 REASONING:\n",
      "The question asks about the format and signature handling of a motion to compel discovery before the Trademark Trial and Appeal Board (TTAB). Relevant information would likely be in sections discussing motions, signature requirements, electronic filing procedures, and service of papers.\n",
      "\n",
      "Chunks 3 and 4 discuss signature of submissions (§ 106.02) and form of submissions (§ 106.03) respectively, important for understanding how motions (including possibly motions to compel discovery) should be formatted and signed.\n",
      "\n",
      "Chunk 13 continues the discussion of signature and disciplinary provisions, emphasizing certification by signatory.\n",
      "\n",
      "Chunks 13 also discusses disciplinary sanctions related to signatures – useful for understanding signature handling.\n",
      "\n",
      "Chunks 113 and 113.01 to 113.06 discuss service of papers including motions, requirements for proof of service, methods of service, and certificates of service, which would be relevant for motions to compel discovery.\n",
      "\n",
      "Chunk 112 describes times for taking action after service which may provide context on timing but less about form.\n",
      "\n",
      "Chunks 0 through 2 provide introductory and general procedural context including references to Federal Rules, but no specific format for motions to compel discovery.\n",
      "\n",
      "Chunks 5-7 describe electronic filing using ESTTA, attachments, and service with proof – critical for current practice.\n",
      "\n",
      "Chunks 18 and 19 discuss extensions of time to oppose, which are less central to motions.\n",
      "\n",
      "Overall, to answer the question well, the best chunks are:\n",
      "- 3 (Signature of submissions)\n",
      "- 4 (Form of submissions)\n",
      "- 7 (Attachments to ESTTA filings)\n",
      "- 113 (Service of papers)\n",
      "- 13 (Signature and certificate for correspondence + disciplinary provisions)\n",
      "\n",
      "Other chunks could add context if needed, but these most directly address the formatting and signature requirements relevant to a motion to compel discovery.\n",
      "\n",
      "DEPTH 1 REASONING:\n",
      "To answer the user's question about the format and signature handling for a motion to compel discovery, I need to focus on TTAB rules regarding document format, signature requirements, electronic filing, and service. Specifically, motions are submissions to the Board, so the rules on \"Form of Submissions\" (§ 106.03, chunk 10-17) and \"Signature of Submissions\" (§ 106.02, chunks 0-6, 13) are relevant. Chunks 3-6 and 13 provide detailed information about signatures—how to sign, who should sign, electronic signatures, and certification effects. Chunks 10-17 discuss submission formatting and electronic filing with ESTTA, which applies to motions. Service information may affect motions to compel discovery, so chunks 113 (likely chunks 25-27) concerning service and proof of service are also needed. These chunks collectively are sufficient to understand the proper formatting and signature handling for filing motions to compel discovery before the TTAB.\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 401 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 435 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 355 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 383 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 396 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 364 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 397 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 402 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 339 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 389 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 387 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 354 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 396 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 384 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 368 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 208 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 383 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 399 tokens\n",
      "Split document into 1 chunks\n",
      "Chunk 0: 393 tokens\n",
      "\n",
      "==== ROUTING AT DEPTH 2 ====\n",
      "Evaluating 19 chunks for relevance\n",
      "Selected chunks: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n",
      "Updated scratchpad:\n",
      "DEPTH 0 REASONING:\n",
      "The question asks about the format and signature handling of a motion to compel discovery before the Trademark Trial and Appeal Board (TTAB). Relevant information would likely be in sections discussing motions, signature requirements, electronic filing procedures, and service of papers.\n",
      "\n",
      "Chunks 3 and 4 discuss signature of submissions (§ 106.02) and form of submissions (§ 106.03) respectively, important for understanding how motions (including possibly motions to compel discovery) should be formatted and signed.\n",
      "\n",
      "Chunk 13 continues the discussion of signature and disciplinary provisions, emphasizing certification by signatory.\n",
      "\n",
      "Chunks 13 also discusses disciplinary sanctions related to signatures – useful for understanding signature handling.\n",
      "\n",
      "Chunks 113 and 113.01 to 113.06 discuss service of papers including motions, requirements for proof of service, methods of service, and certificates of service, which would be relevant for motions to compel discovery.\n",
      "\n",
      "Chunk 112 describes times for taking action after service which may provide context on timing but less about form.\n",
      "\n",
      "Chunks 0 through 2 provide introductory and general procedural context including references to Federal Rules, but no specific format for motions to compel discovery.\n",
      "\n",
      "Chunks 5-7 describe electronic filing using ESTTA, attachments, and service with proof – critical for current practice.\n",
      "\n",
      "Chunks 18 and 19 discuss extensions of time to oppose, which are less central to motions.\n",
      "\n",
      "Overall, to answer the question well, the best chunks are:\n",
      "- 3 (Signature of submissions)\n",
      "- 4 (Form of submissions)\n",
      "- 7 (Attachments to ESTTA filings)\n",
      "- 113 (Service of papers)\n",
      "- 13 (Signature and certificate for correspondence + disciplinary provisions)\n",
      "\n",
      "Other chunks could add context if needed, but these most directly address the formatting and signature requirements relevant to a motion to compel discovery.\n",
      "\n",
      "DEPTH 1 REASONING:\n",
      "To answer the user's question about the format and signature handling for a motion to compel discovery, I need to focus on TTAB rules regarding document format, signature requirements, electronic filing, and service. Specifically, motions are submissions to the Board, so the rules on \"Form of Submissions\" (§ 106.03, chunk 10-17) and \"Signature of Submissions\" (§ 106.02, chunks 0-6, 13) are relevant. Chunks 3-6 and 13 provide detailed information about signatures—how to sign, who should sign, electronic signatures, and certification effects. Chunks 10-17 discuss submission formatting and electronic filing with ESTTA, which applies to motions. Service information may affect motions to compel discovery, so chunks 113 (likely chunks 25-27) concerning service and proof of service are also needed. These chunks collectively are sufficient to understand the proper formatting and signature handling for filing motions to compel discovery before the TTAB.\n",
      "\n",
      "DEPTH 2 REASONING:\n",
      "The user's question focuses on the required format and signature handling for a motion to compel discovery, which is a submission to the TTAB. Such submissions must follow the rules for form and signature of submissions to the Board. Relevant rules are primarily in 37 C.F.R. § 2.193 (signature), 37 C.F.R. § 2.126 (form of submission), and related TTAB provisions. The selected chunks 0-7 and 13 cover signature requirements, including electronic signatures, who must sign, and certification. Chunks 8-15 cover the form and manner of submissions, including ESTTA electronic filing as the required method, exceptions for paper submissions with technical problem explanations, and exhibit handling. Chunks 16-18 discuss proof of service and certificates of service which are important to motions. Since a motion to compel discovery is a substantive filing, it would follow these format and signature rules.\n",
      "\n",
      "Specifically:\n",
      "- Chunks 0-4 give specifics on signature requirements, persons authorized to sign, and certification.\n",
      "- Chunks 5-7 discuss electronic signatures and use of ESTTA for filing and signing.\n",
      "- Chunks 8-15 detail the formatting requirements (font size, spacing, paper size if paper filing), filing methods (ESTTA required, exceptions allowed), and exhibit handling.\n",
      "- Chunks 16-18 explain the service requirements including required certificates of service.\n",
      "\n",
      "Therefore, these chunks provide sufficient detailed information to answer the question about format and signature of a motion to compel discovery before the TTAB.\n",
      "\n",
      "Returning 19 relevant chunks at depth 2\n",
      "\n",
      "==== FIRST 3 RETRIEVED PARAGRAPHS ====\n",
      "\n",
      "PARAGRAPH 1 (ID: 3.0.0):\n",
      "----------------------------------------\n",
      "§ 2.194. 106.02  Signature of Submissions\n",
      "37 C.F.R. § 2.119(e) Every submission filed in an inter partes proceeding, and every request for an extension\n",
      "of time to file an opposition, must be signed by the party filing it, or by the party’s attorney or other authorized\n",
      "representative, but an unsigned submission will not be r efused consideration if a signed copy is submitted\n",
      "to the Office within the time limit set in the notification of this defect by the Office. 37 C.F.R. § 11.14(e) Appearance. No individual other than those specified in par agraphs (a), (b), and (c)\n",
      "of this section will be permitted to pr actice before the Office in tr ademark matters on behalf of a client. Except as specified in § 2.11(a) of this chapter, an individual may appear in a trademark or other non-patent\n",
      "matter in his or her own behalf or on behalf of:\n",
      "(1)   A firm of which he or she is a member;\n",
      "(2)   A partnership of which he or she is a partner; or\n",
      "(3)   A corporation or association of which he or she is an officer and which he or she is authorized to\n",
      "represent. 37 C.F.R. § 11.18 Signature and certificate for correspondence filed in the Office. (a)   For all documents filed in the Office in patent, trademark, and other non-patent matters, and all\n",
      "documents filed with a hearing officer in a disciplinary proceeding, except for correspondence that is\n",
      "required to be signed by the applicant or party, each piece of correspondence filed by a practitioner in the\n",
      "Office must bear a signature, personally signed or inserted by such practitioner, in compliance with §\n",
      "1.4(d)(1), § 1.4(d)(2), or § 2.193(a) of this chapter.\n",
      "----------------------------------------\n",
      "\n",
      "PARAGRAPH 2 (ID: 3.1.0):\n",
      "----------------------------------------\n",
      "(b)    By presenting to the Office or hearing officer in a disciplinary proceeding (whether by signing,\n",
      "filing, submitting, or later advocating) any paper, the party presenting such paper, whether a practitioner\n",
      "or non-practitioner, is certifying that—\n",
      "(1)   All statements made therein of the party’s own knowledge are true, all statements made therein\n",
      "on information and belief are believed to be true, and all statements made therein are made with the\n",
      "knowledge that whoever, in any matter within the jurisdiction of the Office, knowingly and willfully falsifies,\n",
      "conceals, or covers up by any trick, scheme, or device a material fact, or knowingly and willfully makes any\n",
      "false, fictitious, or fraudulent statements or representations, or knowingly and willfully makes or uses any\n",
      "false writing or document knowing the same to contain any false, fictitious, or fraudulent statement or entry,\n",
      "shall be subject to the penalties set forth under 18 U.S.C. 1001 and any other applicable criminal statute,\n",
      "and violations of the provisions of this section may jeopardize the probative value of the paper; and\n",
      "(2)   To the best of the party’s knowledge, information and belief, formed after an inquiry reasonable\n",
      "under the circumstances,\n",
      "(i)   The paper is not being presented for any improper purpose, such as to harass someone or to\n",
      "cause unnecessary delay or needless increase in the cost of any proceeding before the Office;\n",
      "(ii)   The other legal contentions therein are warranted by existing law or by a nonfrivolous\n",
      "argument for the extension, modification, or reversal of existing law or the establishment of new law;\n",
      "June   2024100-15\n",
      "§ 106.02GENERAL INFORMATION\n",
      "(iii)   The allegations and other factual contentions have evidentiary support or, if specifically so\n",
      "identified, are likely to have evidentiary support after a reasonable opportunity for further investigation or\n",
      "discovery; and\n",
      "(iv)    The denials of factual contentions are warranted on the evidence, or if specifically so\n",
      "identified, are reasonably based on a lack of information or belief.\n",
      "----------------------------------------\n",
      "\n",
      "PARAGRAPH 3 (ID: 3.2.0):\n",
      "----------------------------------------\n",
      "(c)    Violations of any of paragraphs (b)(2)(i) through (iv) of this section are, after notice and reasonable\n",
      "opportunity to respond, subject to such sanctions or actions as deemed appropriate by the USPTO Director,\n",
      "which may include, but are not limited to, any combination of--\n",
      "(1)    Striking the offending paper;\n",
      "(2)    Referring a practitioner’s conduct to the Director of Enrollment and Discipline for appropriate\n",
      "action;\n",
      "(3)    Precluding a party or practitioner from submitting a paper, or presenting or contesting an\n",
      "issue;\n",
      "(4)   Affecting the weight given to the offending paper; or\n",
      "(5)    Terminating the proceedings in the Office. (d)    Any practitioner violating the provisions of this section may also be subject to disciplinary action. 37 C.F.R. § 2.193 Trademark correspondence and signature requirements. (a)   Signature required. Each piece of correspondence that requires a signature, must bear:\n",
      "(1)   A handwritten signature personally signed in permanent ink by the person named as the signatory,\n",
      "or a true copy thereof; or\n",
      "(2)   An electronic signature that meets the requirements of paragraph (c) of this section, personally\n",
      "entered by the person named as the signatory. The Office will accept an electronic signature that meets the\n",
      "requirements of paragraph (c) of this section on correspondence filed on paper or through TEAS or ESTTA. (b)   Copy of original signature. If a copy of an original signature is filed, the filer should retain the\n",
      "original as evidence of authenticity. If a question of authenticity arises, the Office may require submission\n",
      "of the original. (c)   Requirements for electronic signature.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the navigation for a sample question\n",
    "question = \"What format should a motion to compel discovery be filed in? How should signatures be handled?\"\n",
    "navigation_result = navigate_to_paragraphs(document_text, question, max_depth=2)\n",
    "\n",
    "# Sample retrieved paragraph\n",
    "print(\"\\n==== FIRST 3 RETRIEVED PARAGRAPHS ====\")\n",
    "for i, paragraph in enumerate(navigation_result[\"paragraphs\"][:3]):\n",
    "    display_id = paragraph.get(\"display_id\", str(paragraph[\"id\"]))\n",
    "    print(f\"\\nPARAGRAPH {i+1} (ID: {display_id}):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(paragraph[\"text\"])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用百万级长文阅读：**GPT-4.1-mini**进行迭代提取文档中的相关要素，并利用草稿板记录解释其思考过程！\n",
    "这个过程表明，GPT-4.1 能像法律分析师一样工作：**逐层深入挖掘相关内容，并解释其推理过程**，这使得我们更容易**调试模型为何选取了这些内容段落**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成答案\n",
    "\n",
    "现在，我们将使用**GPT-4.1** 和先前检索到的段落生成答案。\n",
    "\n",
    "> 这里我们使用了一个巧妙的技巧：**动态构建一个Literal列表**，这样可以**强制模型的回答仅从我们提供的选项中选择**——在本例中是段落 ID。\n",
    "> 不过这有一些限制：**我们最多只能提供一定数量的选项**，所以如果系统需要引用超过 500 个文档，这种方法可能就不适用了。\n",
    "> 在这种情况下，你有两个选择：\n",
    "* 设计一个过滤器，仅保留最多 500 个可能的引用项；\n",
    "* 或者让模型在回答中**明确写出引用的 ID**，之后再通过后处理提取这些引用（例如模型可能会说：“... \\[doc 0.0.12]”，你可以用正则表达式提取出这些引用 ID）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== GENERATING ANSWER ====\n",
      "\n",
      "Answer: A motion to compel discovery must be filed electronically via ESTTA, unless ESTTA is unavailable due to technical problems or extraordinary circumstances, in which case a paper submission is permitted with a written explanation (\"Submissions must be made to the Trademark Trial and Appeal Board via ESTTA\"; \"In the event that ESTTA is unavailable due to technical problems, or when extraordinary circumstances are present, submissions may be filed in paper form. All submissions in paper form... must include a written explanation of such technical problems or extraordinary circumstances\"; 3.3.10.0). \n",
      "\n",
      "For electronic filings, the motion must be in at least 11-point type and double-spaced, and any exhibits must be attached electronically and be clear and legible (\"Text in an electronic submission must be filed in at least 11-point type and double-spaced. Exhibits pertaining to an electronic submission must be made electronically as an attachment to the submission and must be clear and legible\"; 3.3.10.0).\n",
      "\n",
      "Regarding signatures, every submission must be signed by the party filing it, or by the party’s attorney or other authorized representative (\"Every submission filed in an inter partes proceeding... must be signed by the party filing it, or by the party’s attorney or other authorized representative\"; 3.0.0). For electronic filings, the signature must be an electronic signature entered by the signatory, consisting of any combination of letters, numbers, spaces, and/or punctuation marks placed between two forward slash (\"/\") symbols (\"Electronic signatures pursuant to 37 C.F.R. § 2.193(c) are required for electronic filings. The party or its representative enters a 'symbol' that has been adopted as a signature. The Board will accept any combination of letters, numbers, space and/or punctuation marks as a valid signature if it is placed between two forward slash ('/') symbols\"; 3.3.5.0). The electronic signature entered on the ESTTA form is sufficient for the entire submission, including attachments (\"The electronic signature entered on the ESTTA form is sufficient as the required signature for the entire submission, including in the absence of a signature on any attachment to the filing form\"; 3.3.5.0).\n",
      "\n",
      "The signatory’s first and last name, and title or position, must be set forth immediately below or adjacent to the signature (\"The first and last name, and the title or position, of the person who signs a document... must be set forth immediately below or adjacent to the signature\"; 3.3.0).\n",
      "\n",
      "In summary: File the motion electronically via ESTTA in the required format, sign it electronically using the accepted method, and ensure the signatory is properly identified.\n",
      "Citations: ['3.3.10.0', '3.0.0', '3.3.5.0', '3.3.0']\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "class LegalAnswer(BaseModel):\n",
    "    \"\"\"Structured response format for legal questions\"\"\"\n",
    "    answer: str\n",
    "    citations: List[str]\n",
    "    \n",
    "    @field_validator('citations')\n",
    "    def validate_citations(cls, citations, info):\n",
    "        # Access valid_citations from the model_config\n",
    "        valid_citations = info.data.get('_valid_citations', [])\n",
    "        if valid_citations:\n",
    "            for citation in citations:\n",
    "                if citation not in valid_citations:\n",
    "                    raise ValueError(f\"Invalid citation: {citation}. Must be one of: {valid_citations}\")\n",
    "        return citations\n",
    "\n",
    "def generate_answer(question: str, paragraphs: List[Dict[str, Any]], \n",
    "                   scratchpad: str) -> LegalAnswer:\n",
    "    \"\"\"Generate an answer from the retrieved paragraphs.\"\"\"\n",
    "    print(\"\\n==== GENERATING ANSWER ====\")\n",
    "    \n",
    "    # Extract valid citation IDs\n",
    "    valid_citations = [str(p.get(\"display_id\", str(p[\"id\"]))) for p in paragraphs]\n",
    "    \n",
    "    if not paragraphs:\n",
    "        return LegalAnswer(\n",
    "            answer=\"I couldn't find relevant information to answer this question in the document.\",\n",
    "            citations=[],\n",
    "            _valid_citations=[]\n",
    "        )\n",
    "    \n",
    "    # Prepare context for the model\n",
    "    context = \"\"\n",
    "    for paragraph in paragraphs:\n",
    "        display_id = paragraph.get(\"display_id\", str(paragraph[\"id\"]))\n",
    "        context += f\"PARAGRAPH {display_id}:\\n{paragraph['text']}\\n\\n\"\n",
    "    \n",
    "    system_prompt = \"\"\"You are a legal research assistant answering questions about the \n",
    "Trademark Trial and Appeal Board Manual of Procedure (TBMP).\n",
    "\n",
    "Answer questions based ONLY on the provided paragraphs. Do not rely on any foundation knowledge or external information or extrapolate from the paragraphs.\n",
    "Cite phrases of the paragraphs that are relevant to the answer. This will help you be more specific and accurate.\n",
    "Include citations to paragraph IDs for every statement in your answer. Valid citation IDs are: {valid_citations_str}\n",
    "Keep your answer clear, precise, and professional.\n",
    "\"\"\"\n",
    "    valid_citations_str = \", \".join(valid_citations)\n",
    "    \n",
    "    # Call the model using structured output\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt.format(valid_citations_str=valid_citations_str)},\n",
    "            {\"role\": \"user\", \"content\": f\"QUESTION: {question}\\n\\nSCRATCHPAD (Navigation reasoning):\\n{scratchpad}\\n\\nPARAGRAPHS:\\n{context}\"}\n",
    "        ],\n",
    "        text_format=LegalAnswer,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    # Add validation information after parsing\n",
    "    response.output_parsed._valid_citations = valid_citations\n",
    "    \n",
    "    print(f\"\\nAnswer: {response.output_parsed.answer}\")\n",
    "    print(f\"Citations: {response.output_parsed.citations}\")\n",
    "\n",
    "    return response.output_parsed\n",
    "\n",
    "# Generate an answer\n",
    "answer = generate_answer(question, navigation_result[\"paragraphs\"], \n",
    "                       navigation_result[\"scratchpad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 结果验证\n",
    "\n",
    "首先看一下具体的引用片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== CITED PARAGRAPHS ====\n",
      "\n",
      "PARAGRAPH 1 (ID: 3.0.0):\n",
      "----------------------------------------\n",
      "§ 2.194. 106.02  Signature of Submissions\n",
      "37 C.F.R. § 2.119(e) Every submission filed in an inter partes proceeding, and every request for an extension\n",
      "of time to file an opposition, must be signed by the party filing it, or by the party’s attorney or other authorized\n",
      "representative, but an unsigned submission will not be r efused consideration if a signed copy is submitted\n",
      "to the Office within the time limit set in the notification of this defect by the Office. 37 C.F.R. § 11.14(e) Appearance. No individual other than those specified in par agraphs (a), (b), and (c)\n",
      "of this section will be permitted to pr actice before the Office in tr ademark matters on behalf of a client. Except as specified in § 2.11(a) of this chapter, an individual may appear in a trademark or other non-patent\n",
      "matter in his or her own behalf or on behalf of:\n",
      "(1)   A firm of which he or she is a member;\n",
      "(2)   A partnership of which he or she is a partner; or\n",
      "(3)   A corporation or association of which he or she is an officer and which he or she is authorized to\n",
      "represent. 37 C.F.R. § 11.18 Signature and certificate for correspondence filed in the Office. (a)   For all documents filed in the Office in patent, trademark, and other non-patent matters, and all\n",
      "documents filed with a hearing officer in a disciplinary proceeding, except for correspondence that is\n",
      "required to be signed by the applicant or party, each piece of correspondence filed by a practitioner in the\n",
      "Office must bear a signature, personally signed or inserted by such practitioner, in compliance with §\n",
      "1.4(d)(1), § 1.4(d)(2), or § 2.193(a) of this chapter.\n",
      "----------------------------------------\n",
      "\n",
      "PARAGRAPH 2 (ID: 3.3.0):\n",
      "----------------------------------------\n",
      "A person signing a document electronically must:\n",
      "(1)   Personally enter any combination of letters, numbers, spaces and/or punctuation marks that the\n",
      "signer has adopted as a signature, placed between two forward slash (“/”) symbols in the signature block\n",
      "on the electronic submission; or\n",
      "(2)   Sign the verified statement using some other form of electronic signature specified by the Director. (d)   Signatory must be identified. The first and last name, and the title or position, of the person who\n",
      "signs a document in connection with a trademark application, registration, or proceeding before the\n",
      "Trademark Trial and Appeal Board must be set forth immediately below or adjacent to the signature. (e)   Proper person to sign. Documents filed in connection with a trademark application or registration\n",
      "must be signed as specified in paragraphs (e)(1) through (9) of this section. (2)   Responses, amendments to applications, requests for express abandonment, requests for\n",
      "reconsideration of final actions, and requests to divide. Responses to Office actions, amendments to\n",
      "applications, requests for express abandonment, requests for reconsideration of final actions, and requests\n",
      "to divide must be signed by the owner of the application or registration, someone with legal authority to\n",
      "bind the owner (e.g. a corporate officer or general partner of a partnership), or a practitioner qualified to\n",
      "practice under § 11.14 of this chapter, in accordance with the following guidelines:\n",
      "100-16June   2024\n",
      "TRADEMARK TRIAL AND APPEAL BOARD MANUAL OF PROCEDURE§ 106.02\n",
      "(ii)   If the owner is not represented by a practitioner qualified to practice under § 11.14 of this\n",
      "chapter, the individual owner or someone with legal authority to bind the owner (e.g., a corporate officer\n",
      "or general partner of a partnership) must sign.\n",
      "----------------------------------------\n",
      "\n",
      "PARAGRAPH 3 (ID: 3.3.5.0):\n",
      "----------------------------------------\n",
      "Electronic\n",
      "signatures pursuant to 37 C.F.R. § 2.193(c) are required for electronic filings. The party or its representative\n",
      "enters a “symbol” that has been adopted as a signature. The Board will accept any combination of letters,\n",
      "numbers, space and/or punctuation marks as a valid signature if it is placed between two forward slash (“/”)\n",
      "symbols. [Note 2.] The electronic signature entered on the ESTTA form is sufficient as the required signature\n",
      "for the entire submission, including in the absence of a signature on any attachment to the filing form. [Note\n",
      "3.] The electronic filing cover sheet in ESTTA must be signed by the party filing it, the party’s attorney or\n",
      "other authorized representative, as appropriate. For further information regarding the filing of submissions\n",
      "using ESTTA, see TBMP § 110. A party may act in its own behalf in a proceeding before the Board, if the party is domiciled in the United\n",
      "States, or an attorney may represent the party. [Note 4.] See TBMP § 114 (Representation of a Party). When an individual who is a party to a Board proceeding elects to act in the indi vidual's own behalf, the\n",
      "individual must sign any documents that are filed with the Board. If a party which is a partnership elects to\n",
      "act in its own behalf, a partner should sign documents filed by the partnership. If a party which is a corporation\n",
      "or association elects to act in its own behalf, an officer thereof who is authorized to sign for the corporation\n",
      "or association should sign for that corporation or association. If joint applicants elect to act on their o wn\n",
      "behalf, all joint applicants must sign any documents filed with the Board. [Note 5.]\n",
      "----------------------------------------\n",
      "\n",
      "PARAGRAPH 4 (ID: 3.3.10.0):\n",
      "----------------------------------------\n",
      "§ 2.119(e);  Birlinn Ltd. v. Stewart, 111 USPQ2d 1905, 1908 (TTAB 2014) (Board applies\n",
      "opportunity to cure pro vision in 2.119(e) to improperly signed papers, which defines the time period for\n",
      "cure as “within the time limit set in the notification of this defect by the Office”). 106.03  Form of Submissions\n",
      "37 C.F.R. § 2.126 Form of submissions to the Trademark Trial and Appeal Board. (a)   Submissions must be made to the Trademark Trial and Appeal Board via ESTTA. (1)   Text in an electronic submission must be filed in at least 11-point type and double-spaced. (2)   Exhibits pertaining to an electronic submission must be made electronically as an attachment\n",
      "to the submission and must be clear and legible. (b)   In the event that ESTTA is unavailable due to technical problems, or when extraordinary\n",
      "circumstances are present, submissions may be filed in paper form. All submissions in paper form, except\n",
      "the extensions of time to file a notice of opposition, the notice of opposition, the petition to cancel, or answers\n",
      "thereto (see §§ 2.101(b)(2), 2.102(a)(2), 2.106(b)(1), 2.111(c)(2), and 2.114(b)(1)), must include a written\n",
      "explanation of such technical problems or extraordinary circumstances. Paper submissions that do not meet\n",
      "the showing required under this paragraph (b) will not be considered.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cited_paragraphs = []\n",
    "for paragraph in navigation_result[\"paragraphs\"]:\n",
    "    para_id = str(paragraph.get(\"display_id\", str(paragraph[\"id\"])))\n",
    "    if para_id in answer.citations:\n",
    "        cited_paragraphs.append(paragraph)\n",
    "    \n",
    "\n",
    "# Display the cited paragraphs for the audience\n",
    "print(\"\\n==== CITED PARAGRAPHS ====\")\n",
    "for i, paragraph in enumerate(cited_paragraphs):\n",
    "    display_id = paragraph.get(\"display_id\", str(paragraph[\"id\"]))\n",
    "    print(f\"\\nPARAGRAPH {i+1} (ID: {display_id}):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(paragraph[\"text\"])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用`LLM-as-judge`对答案进行验证 （o4-mini）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== VERIFYING ANSWER ====\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Invalid prompt: your prompt was flagged as potentially violating our usage policy. Please try again with a different prompt: https://platform.openai.com/docs/guides/reasoning#advice-on-prompting', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_prompt'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39moutput_parsed\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Verify the answer using only the cited paragraphs\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m verification \u001b[38;5;241m=\u001b[39m \u001b[43mverify_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcited_paragraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Display final result with verification\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== FINAL VERIFIED ANSWER ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m, in \u001b[0;36mverify_answer\u001b[0;34m(question, answer, cited_paragraphs)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Prepare system prompt\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a legal assistant. Your job is to analyze whether a provided answer is well-supported by the following source paragraphs. \u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mExplain how well the content aligns with the source, and provide an assessment of completeness, precision, and relevance.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 36\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo4-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;43mQUESTION: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;43mANSWER TO VERIFY:\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43manswer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manswer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43mCITATIONS USED: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcitations\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;43mSOURCE PARAGRAPHS:\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;43mIs this answer accurate and properly supported by the source paragraphs?\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;43mAssign a confidence level (high, medium, or low) based on completeness and accuracy.\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;43m            \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVerificationResult\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Log and return the verification result\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAccuracy verification: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPASSED\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mresponse\u001b[38;5;241m.\u001b[39moutput_parsed\u001b[38;5;241m.\u001b[39mis_accurate\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/reader/lib/python3.10/site-packages/openai/resources/responses/responses.py:936\u001b[0m, in \u001b[0;36mResponses.parse\u001b[0;34m(self, input, model, text_format, tools, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, store, stream, temperature, text, tool_choice, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_response: Response) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedResponse[TextFormatT]:\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_response(\n\u001b[1;32m    931\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    932\u001b[0m         text_format\u001b[38;5;241m=\u001b[39mtext_format,\n\u001b[1;32m    933\u001b[0m         response\u001b[38;5;241m=\u001b[39mraw_response,\n\u001b[1;32m    934\u001b[0m     )\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/responses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_output_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprevious_response_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResponseCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `Response` instance into a `ParsedResponse`\u001b[39;49;00m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedResponse\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTextFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/reader/lib/python3.10/site-packages/openai/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/reader/lib/python3.10/site-packages/openai/_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Invalid prompt: your prompt was flagged as potentially violating our usage policy. Please try again with a different prompt: https://platform.openai.com/docs/guides/reasoning#advice-on-prompting', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_prompt'}}"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any, Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class VerificationResult(BaseModel):\n",
    "    \"\"\"Verification result format\"\"\"\n",
    "    is_accurate: bool\n",
    "    explanation: str\n",
    "    confidence: Literal[\"high\", \"medium\", \"low\"]\n",
    "\n",
    "def verify_answer(question: str, answer: LegalAnswer, \n",
    "                 cited_paragraphs: List[Dict[str, Any]]) -> VerificationResult:\n",
    "    \"\"\"\n",
    "    Verify if the answer is grounded in the cited paragraphs.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        answer: The generated answer\n",
    "        cited_paragraphs: Paragraphs cited in the answer\n",
    "        \n",
    "    Returns:\n",
    "        Verification result with accuracy assessment, explanation, and confidence level\n",
    "    \"\"\"\n",
    "    print(\"\\n==== VERIFYING ANSWER ====\")\n",
    "    \n",
    "    # Prepare context with the cited paragraphs\n",
    "    context = \"\"\n",
    "    for paragraph in cited_paragraphs:\n",
    "        display_id = paragraph.get(\"display_id\", str(paragraph[\"id\"]))\n",
    "        context += f\"PARAGRAPH {display_id}:\\n{paragraph['text']}\\n\\n\"\n",
    "    \n",
    "    # Prepare system prompt\n",
    "    system_prompt = \"\"\"You are a legal assistant. Your job is to analyze whether a provided answer is well-supported by the following source paragraphs. \n",
    "Explain how well the content aligns with the source, and provide an assessment of completeness, precision, and relevance.\"\"\"\n",
    "\n",
    "    \n",
    "    response = client.responses.parse(\n",
    "        model=\"o4-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWER TO VERIFY:\n",
    "{answer.answer}\n",
    "\n",
    "CITATIONS USED: {', '.join(answer.citations)}\n",
    "\n",
    "SOURCE PARAGRAPHS:\n",
    "{context}\n",
    "\n",
    "Is this answer accurate and properly supported by the source paragraphs?\n",
    "Assign a confidence level (high, medium, or low) based on completeness and accuracy.\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        text_format=VerificationResult\n",
    "    )\n",
    "    \n",
    "    # Log and return the verification result\n",
    "    print(f\"\\nAccuracy verification: {'PASSED' if response.output_parsed.is_accurate else 'FAILED'}\")\n",
    "    print(f\"Confidence: {response.output_parsed.confidence}\")\n",
    "    print(f\"Explanation: {response.output_parsed.explanation}\")\n",
    "    \n",
    "    return response.output_parsed\n",
    "\n",
    "# Verify the answer using only the cited paragraphs\n",
    "verification = verify_answer(question, answer, cited_paragraphs)\n",
    "\n",
    "# Display final result with verification\n",
    "print(\"\\n==== FINAL VERIFIED ANSWER ====\")\n",
    "print(f\"Verification: {'PASSED' if verification.is_accurate else 'FAILED'} | Confidence: {verification.confidence}\")\n",
    "print(\"\\nAnswer:\")\n",
    "print(answer.answer)\n",
    "print(\"\\nCitations:\")\n",
    "for citation in answer.citations:\n",
    "    print(f\"- {citation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 成本消耗\n",
    "我们来拆解一下这种 Agentic RAG 方法的成本结构：\n",
    "### 预计的固定成本 vs. 变量成本\n",
    "* **固定的一次性开销:**  \n",
    "  * **传统RAG:** ~$0.43 (embedding + metadata generation)\n",
    "  * **Agentic RAG:** $0.00 \n",
    "\n",
    "* **每次查询开销:**  \n",
    "  * **Router Model (`gpt-4.1-mini`):**  \n",
    "    * I初始路由 (20 chunks): ~$0.10  \n",
    "    * 多级迭代递归: ~$0.20\n",
    "  * **生成答案 (`gpt-4.1`):** ~$0.05\n",
    "  * **验证 (`o4-mini`):** ~$0.01\n",
    "  * **总共** ~$0.36\n",
    "\n",
    "尽管每次查询的成本高于传统RAG，但这种方法具有以下优势：\n",
    "\n",
    "* 可立即从新文档中获取结果\n",
    "* 更精确的引用\n",
    "* 更好地处理转述和概念性问题\n",
    "* 无需维护基础设施\n",
    "\n",
    "\n",
    "## 与传统RAG的优势与权衡\n",
    "\n",
    "### 优势\n",
    "\n",
    "* **零预处理延迟**：无需预处理即可立即回答新文档中的问题。\n",
    "* **动态查询**：模仿人类阅读模式，聚焦于更有前景的文档片段。\n",
    "* **跨片段推理能力**：模型能够发现不同文档片段之间的关联，这种关联可能被传统独立片段检索所忽略，从而提高生成答案的准确性，并节省优化检索管道的时间。\n",
    "\n",
    "### 权衡\n",
    "\n",
    "* **更高的每次查询成本**：与基于嵌入的检索相比，每次查询需要更多的计算。\n",
    "* **增加延迟**：分层导航处理的时间长于简单的向量查找。\n",
    "* **有限的可扩展性**：在极大规模文档集合中，预处理可能更有效，此方法可能会遇到困难。\n",
    "\n",
    "## 后续可改进的点\n",
    "\n",
    "针对目前的方案，我们可以进行以下优化和扩展：\n",
    "\n",
    "* **生成知识图谱**：我们可以利用GPT 4.1-mini的大型上下文窗口，迭代地生成详细的知识图谱，随后GPT 4.1可以基于此图谱回答问题，这样只需“摄入”一次文档，无需每次重新导航。\n",
    "* **增强的暂存工具（Scratchpad）**：可以为暂存工具提供更多选择，例如编辑或删除已有记忆。这允许模型更灵活地选择与当前问题最相关的记忆片段。\n",
    "* **调整导航深度**：我们可以通过调整分层导航的深度，平衡成本与性能。某些场景（如法律文档）可能需要精确到句子级别的引用，而其他场景（如新闻文章）可能只需要段落级别的引用即可。\n",
    "\n",
    "## 关键核心总结\n",
    "\n",
    "1. **上下文窗口能力超凡**：百万token的上下文窗口使即时导航文档成为可能。\n",
    "2. **分层方法模拟人类阅读**：智能路由方法类似人类快速浏览文档中的相关片段。\n",
    "3. **暂存工具支持多步推理**：保留推理记录能够提高导航质量。\n",
    "4. **快速实现，无需数据库**：整个系统完全可以通过API调用搭建，不需要额外的基础设施。\n",
    "5. **验证机制提高可靠性**：使用模型自身进行判断的模式能在结果交付用户前捕获错误。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
